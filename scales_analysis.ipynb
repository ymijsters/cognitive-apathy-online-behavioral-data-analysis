{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Survey Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAS Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scoring complete! Limited results saved to 'das_scored_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"Pilot Data/redcap_responses.csv\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Subscale items (by question number)\n",
    "executive_positive = [1, 6, 11, 17, 19, 21, 23]  \n",
    "executive_negative = [10] # Reverse-scored\n",
    "\n",
    "emotional_positive = [3, 5, 7, 9, 20]  # Reverse-scored\n",
    "emotional_negative = [12, 15, 24]\n",
    "\n",
    "initiation_positive = [2, 4, 8, 13, 14, 16, 18, 22]  # Reverse-scored\n",
    "\n",
    "# Max scale value (assuming 3-point scale from your data: 0-3)\n",
    "MAX_SCORE = 3\n",
    "\n",
    "def reverse_score(value):\n",
    "    \"\"\"Reverse score for negatively scored items\"\"\"\n",
    "    if pd.isnull(value):\n",
    "        return 0  # or None, depending on how you want to handle missing data\n",
    "    return MAX_SCORE - value\n",
    "\n",
    "# Scoring Function\n",
    "def score_participant(row):\n",
    "    try:\n",
    "        das_executive_score = sum([\n",
    "            row.get(f'das_{i}', 0) for i in executive_positive\n",
    "        ]) + sum([\n",
    "            reverse_score(row.get(f'das_{i}', 0)) for i in executive_negative\n",
    "        ])\n",
    "\n",
    "        das_emotional_score = sum([\n",
    "            row.get(f'das_{i}', 0) for i in emotional_positive\n",
    "        ]) + sum([\n",
    "            reverse_score(row.get(f'das_{i}', 0)) for i in emotional_negative\n",
    "        ])\n",
    "\n",
    "        das_initiation_score = sum([\n",
    "            row.get(f'das_{i}', 0) for i in initiation_positive\n",
    "        ])\n",
    "\n",
    "        total_score = das_executive_score + das_emotional_score + das_initiation_score\n",
    "\n",
    "        return pd.Series([das_executive_score, das_emotional_score, das_initiation_score, total_score])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return pd.Series([None, None, None, None])\n",
    "\n",
    "# Apply scoring function and assign column names directly\n",
    "df[['das_executive_score', 'das_emotional_score', 'das_initiation_score', 'das_total_score']] = df.apply(\n",
    "    score_participant, axis=1\n",
    ")\n",
    "\n",
    "# Rename prolific_id to participant_id and select output columns\n",
    "output_df = df[['prolific_id', 'das_executive_score', 'das_emotional_score', 'das_initiation_score', 'das_total_score']].rename(\n",
    "    columns={'prolific_id': 'participant_id'}\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv(\"Pilot Data/das_scored_results.csv\", index=False)\n",
    "\n",
    "print(\"✅ Scoring complete! Limited results saved to 'das_scored_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUIP Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QUIP-RS scoring complete! Results saved to 'quip_results_scored.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"Pilot Data/redcap_responses.csv\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Reverse any spelling errors in column names (e.g., 'repeating_activites_2' → 'repeating_activities_2')\n",
    "df = df.rename(columns={\n",
    "    'repeating_activites_2': 'repeating_activities_2'\n",
    "})\n",
    "\n",
    "# Define ICD subscales\n",
    "gambling_items = ['gambling', 'gambling_2', 'gambling_3', 'gambling_4']\n",
    "sex_items = ['sex', 'sex_2', 'sex_3', 'sex_4']\n",
    "buying_items = ['buying', 'buying_2', 'buying_3', 'buying_4']\n",
    "eating_items = ['eating', 'eating_2', 'eating_3', 'eating_4']\n",
    "\n",
    "# Punding / Hobbyism combines 'perform_task' + 'repeating_activities' across items\n",
    "performing_task_items = ['perform_task', 'performing_task_2', 'performing_tasks_3', 'performing_tasks_4']\n",
    "repeating_activities_items = ['repeating_activities', 'repeating_activities_2', 'repeating_activities_3', 'repeating_activities_4']\n",
    "\n",
    "# Scoring function\n",
    "def score_quip_rs(row):\n",
    "    try:\n",
    "        # Sum subscales\n",
    "        prolific_id = row['prolific_id']\n",
    "        gambling_score = sum([row.get(item, 0) for item in gambling_items])\n",
    "        sex_score = sum([row.get(item, 0) for item in sex_items])\n",
    "        buying_score = sum([row.get(item, 0) for item in buying_items])\n",
    "        eating_score = sum([row.get(item, 0) for item in eating_items])\n",
    "        \n",
    "        # Punding/Hobbyism score (sum of both sets of items)\n",
    "        hobbyism_punding_score = (\n",
    "            sum([row.get(item, 0) for item in performing_task_items]) +\n",
    "            sum([row.get(item, 0) for item in repeating_activities_items])\n",
    "        )\n",
    "        \n",
    "        # ICD Total (sum of subscales)\n",
    "        icd_total = gambling_score + sex_score + buying_score + eating_score \n",
    "        \n",
    "        # QUIP-RS Total (same as ICD total if no other domains are included)\n",
    "        quip_rs_total = icd_total + hobbyism_punding_score\n",
    "        \n",
    "        return pd.Series([\n",
    "            prolific_id,\n",
    "            gambling_score,\n",
    "            sex_score,\n",
    "            buying_score,\n",
    "            eating_score,\n",
    "            hobbyism_punding_score,\n",
    "            icd_total,\n",
    "            quip_rs_total\n",
    "        ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in scoring row: {e}\")\n",
    "        return pd.Series([None]*7)\n",
    "\n",
    "# Apply scoring\n",
    "df[['prolific_id','gambling_score', 'sex_score', 'buying_score', 'eating_score', 'hobbyism_punding_score', 'icd_total', 'quip_rs_total']] = df.apply(\n",
    "    score_quip_rs, axis=1\n",
    ")\n",
    "\n",
    "# Create final output dataframe: participant_id + scores\n",
    "output_df = df[['prolific_id','gambling_score', 'sex_score', 'buying_score', 'eating_score', 'hobbyism_punding_score', 'icd_total', 'quip_rs_total']].rename(\n",
    "    columns={'prolific_id': 'participant_id'}\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv(\"Pilot Data/quip_results_scored.csv\", index=False)\n",
    "\n",
    "print(\"✅ QUIP-RS scoring complete! Results saved to 'quip_results_scored.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HADS Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HADS scoring complete! Results saved to 'hads_results_scored.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv(\"Pilot Data/redcap_responses.csv\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Scoring maps: index → score\n",
    "reverse_scoring = {0: 3, 1: 2, 2: 1, 3: 0}\n",
    "standard_scoring = {0: 0, 1: 1, 2: 2, 3: 3}\n",
    "\n",
    "# Define item lists by scale\n",
    "anxiety_items = {\n",
    "    'hads_1': reverse_scoring,\n",
    "    'hads_3': reverse_scoring,\n",
    "    'hads_5': reverse_scoring,\n",
    "    'hads_7': standard_scoring,\n",
    "    'hads_9': standard_scoring,\n",
    "    'hads_11': reverse_scoring,\n",
    "    'hads_13': reverse_scoring\n",
    "}\n",
    "\n",
    "depression_items = {\n",
    "    'hads_2': standard_scoring,\n",
    "    'hads_4': standard_scoring,\n",
    "    'hads_6': reverse_scoring,\n",
    "    'hads_8': reverse_scoring,\n",
    "    'hads_10': reverse_scoring,\n",
    "    'hads_12': standard_scoring,\n",
    "    'hads_14': standard_scoring\n",
    "}\n",
    "\n",
    "# Scoring function for HADS\n",
    "def score_hads(row):\n",
    "    try:\n",
    "        hads_anxiety_score = 0\n",
    "        hads_depression_score = 0\n",
    "\n",
    "        # Score Anxiety items\n",
    "        for item, scoring_map in anxiety_items.items():\n",
    "            response_index = row.get(item, None)\n",
    "            if pd.isnull(response_index):\n",
    "                score = 0  # or handle NaN differently\n",
    "            else:\n",
    "                score = scoring_map.get(response_index, 0)\n",
    "            hads_anxiety_score += score\n",
    "\n",
    "        # Score Depression items\n",
    "        for item, scoring_map in depression_items.items():\n",
    "            response_index = row.get(item, None)\n",
    "            if pd.isnull(response_index):\n",
    "                score = 0  # or handle NaN differently\n",
    "            else:\n",
    "                score = scoring_map.get(response_index, 0)\n",
    "            hads_depression_score += score\n",
    "\n",
    "        hads_total_score = hads_anxiety_score + hads_depression_score\n",
    "\n",
    "        return pd.Series([hads_anxiety_score, hads_depression_score, hads_total_score])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in scoring HADS row: {e}\")\n",
    "        return pd.Series([None, None, None])\n",
    "\n",
    "# Apply scoring\n",
    "df[['hads_anxiety_score', 'hads_depression_score', 'hads_total_score']] = df.apply(\n",
    "    score_hads, axis=1\n",
    ")\n",
    "\n",
    "# Prepare final output dataframe\n",
    "output_df = df[['prolific_id', 'hads_anxiety_score', 'hads_depression_score', 'hads_total_score']].rename(\n",
    "    columns={'prolific_id': 'participant_id'}\n",
    ")\n",
    "\n",
    "# Export to CSV\n",
    "output_df.to_csv(\"Pilot Data/hads_results_scored.csv\", index=False)\n",
    "\n",
    "print(\"✅ HADS scoring complete! Results saved to 'hads_results_scored.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LARS Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring complete! File saved as 'lars_results_scored.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"Pilot Data/redcap_responses.csv\")\n",
    "\n",
    "# Optional reverse scoring (add column names as needed)\n",
    "reverse_scored_items = []  # Example: ['ic_i_3', 'ai_ep_2']\n",
    "MAX_SCORE = 4\n",
    "\n",
    "# Reverse scoring function\n",
    "def reverse_score(row, col):\n",
    "    if col in reverse_scored_items:\n",
    "        return MAX_SCORE - row[col]\n",
    "    else:\n",
    "        return row[col]\n",
    "\n",
    "# Apply reverse scoring to all item columns\n",
    "all_item_cols = [\n",
    "    col for col in df.columns \n",
    "    if col.startswith(('e_er_', 'ai_ep_', 'ai_i_', 'ic_n_', 'ic_m_', 'ic_i_', 'ic_s_', 'sa_'))\n",
    "]\n",
    "\n",
    "# Apply reverse scoring\n",
    "for col in all_item_cols:\n",
    "    df[col] = df.apply(lambda row: reverse_score(row, col), axis=1)\n",
    "\n",
    "# Score calculations\n",
    "df['Intellectual_Curiosity'] = 125 - df[[col for col in df.columns if col.startswith('ic_')]].sum(axis=1)\n",
    "df['Motivation'] = 40 - df[[col for col in df.columns if col.startswith('ic_m_')]].sum(axis=1)\n",
    "df['Interest'] = 20 - df[[col for col in df.columns if col.startswith('ic_i_')]].sum(axis=1)\n",
    "df['Novelty_Seeking'] = 30 - df[[col for col in df.columns if col.startswith('ic_n_')]].sum(axis=1)\n",
    "df['Social_Life'] = 35 - df[[col for col in df.columns if col.startswith('ic_s_')]].sum(axis=1)\n",
    "\n",
    "df['Emotional_Responsiveness'] = df[[col for col in df.columns if col.startswith('e_er_')]].sum(axis=1)\n",
    "df['Emotional_Apathy'] = df['Emotional_Responsiveness']  # Same thing, different label\n",
    "\n",
    "df['Self_Awareness'] = 40 - df[[col for col in df.columns if col.startswith('sa_')]].sum(axis=1)\n",
    "\n",
    "df['Action_Initiation'] = 55 - df[[col for col in df.columns if col.startswith('ai_ep_') or col.startswith('ai_i_')]].sum(axis=1)\n",
    "df['Everyday_Productivity'] = 25 - df[[col for col in df.columns if col.startswith('ai_ep_')]].sum(axis=1)\n",
    "df['Initiative'] = 30 - df[[col for col in df.columns if col.startswith('ai_i_')]].sum(axis=1)\n",
    "\n",
    "# Total LARS Score\n",
    "df['Total_LARS_Score'] = 255 - df[all_item_cols].sum(axis=1)\n",
    "\n",
    "# Select output columns\n",
    "output_cols = [\n",
    "    'prolific_id', 'Intellectual_Curiosity', 'Motivation', 'Interest',\n",
    "    'Novelty_Seeking', 'Social_Life', 'Emotional_Responsiveness', 'Self_Awareness',\n",
    "    'Action_Initiation', 'Everyday_Productivity', 'Initiative', 'Total_LARS_Score'\n",
    "]\n",
    "\n",
    "df_results = df[output_cols]\n",
    "\n",
    "df_results = df_results.rename(\n",
    "    columns={'prolific_id': 'participant_id'}\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df_results.to_csv('Pilot Data/lars_results_scored.csv', index=False)\n",
    "\n",
    "print(\"Scoring complete! File saved as 'lars_results_scored.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Scale Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we correlate DAS with overall Acceptance Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             participant_id  das_executive_score  das_emotional_score  \\\n",
      "0  67ac2151e5b37e0b91a5af0e                    4                   12   \n",
      "1  66b5a7ae36e5b931db863954                    3                   10   \n",
      "2  678fa07cd72c816bac76bda5                    3                   10   \n",
      "3  6785b7dd6705050739feb0ad                    5                   15   \n",
      "4  5adef850eb60400001539109                    8                   18   \n",
      "\n",
      "   das_initiation_score  das_total_score  acceptance_rate  \n",
      "0                    10               26         0.698333  \n",
      "1                    14               27         0.433333  \n",
      "2                     7               20         0.665000  \n",
      "3                    13               33         0.536667  \n",
      "4                    13               39         0.073333  \n",
      "Correlation between subscale scores and acceptance rates (with p-values):\n",
      "das_executive_score: Correlation = 0.078, p-value = 0.830\n",
      "das_emotional_score: Correlation = -0.551, p-value = 0.099\n",
      "das_initiation_score: Correlation = -0.332, p-value = 0.348\n",
      "das_total_score: Correlation = -0.336, p-value = 0.342\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Load the EBDM task data\n",
    "df = pd.read_csv(\"Pilot Data/all_trials.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Calculate the overall acceptance rate per block for each participant\n",
    "participant_acceptance_rate = df.groupby(['participant_id'])['acceptance'].mean().reset_index()\n",
    "\n",
    "# Rename the column to 'acceptance_rate'\n",
    "participant_acceptance_rate.rename(columns={'acceptance': 'acceptance_rate'}, inplace=True)\n",
    "\n",
    "#print(block_acceptance_rate.head())\n",
    "\n",
    "das_data = pd.read_csv(\"Pilot Data/das_scored_results.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Preview the aggregated subscale data\n",
    "#print(subscale_avg.head())\n",
    "\n",
    "# Merge the subscale averages with the block acceptance rates based on participant_id and block\n",
    "merged_data = pd.merge(das_data, participant_acceptance_rate, on=['participant_id'])\n",
    "\n",
    "# Preview the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Initialize a dictionary to store correlation coefficients and p-values\n",
    "correlation_results = {}\n",
    "\n",
    "\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_executive_score'], merged_data['acceptance_rate'])\n",
    "correlation_results['das_executive_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_emotional_score'], merged_data['acceptance_rate'])\n",
    "correlation_results['das_emotional_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_initiation_score'], merged_data['acceptance_rate'])\n",
    "correlation_results['das_initiation_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_total_score'], merged_data['acceptance_rate'])\n",
    "correlation_results['das_total_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "# Store the results\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlation between subscale scores and acceptance rates (with p-values):\")\n",
    "for subscale, results in correlation_results.items():\n",
    "    print(f\"{subscale}: Correlation = {results['correlation']:.3f}, p-value = {results['p_value']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second we correlate LARS with overall Acceptance Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             participant_id  Intellectual_Curiosity  Motivation  Interest  \\\n",
      "0  67ac2151e5b37e0b91a5af0e                      20           7         5   \n",
      "1  66b5a7ae36e5b931db863954                      28           8         5   \n",
      "2  678fa07cd72c816bac76bda5                      33           9         4   \n",
      "3  6785b7dd6705050739feb0ad                      44           8         6   \n",
      "4  5adef850eb60400001539109                      47          12         6   \n",
      "\n",
      "   Novelty_Seeking  Social_Life  Emotional_Responsiveness  Self_Awareness  \\\n",
      "0                4            4                        24              16   \n",
      "1                6            9                        35               4   \n",
      "2                8           12                        27               6   \n",
      "3               10           20                        24               7   \n",
      "4               12           17                        25              16   \n",
      "\n",
      "   Action_Initiation  Everyday_Productivity  Initiative  Total_LARS_Score  \\\n",
      "0                 10                      8           2                57   \n",
      "1                  6                      4           2                38   \n",
      "2                 12                      7           5                59   \n",
      "3                 15                      9           6                77   \n",
      "4                 12                      6           6                85   \n",
      "\n",
      "   acceptance_rate  \n",
      "0         0.698333  \n",
      "1         0.433333  \n",
      "2         0.665000  \n",
      "3         0.536667  \n",
      "4         0.073333  \n",
      "Correlation between subscale scores and acceptance rates (with p-values):\n",
      "Intellectual_Curiosity: Correlation = -0.623, p-value = 0.054\n",
      "Emotional_Responsiveness: Correlation = 0.325, p-value = 0.359\n",
      "Self_Awareness: Correlation = -0.568, p-value = 0.087\n",
      "Action_Initiation: Correlation = -0.154, p-value = 0.671\n",
      "Total_LARS_Score: Correlation = -0.595, p-value = 0.070\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Load the EBDM task data\n",
    "df = pd.read_csv(\"Pilot Data/all_trials.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Calculate the overall acceptance rate per block for each participant\n",
    "participant_acceptance_rate = df.groupby(['participant_id'])['acceptance'].mean().reset_index()\n",
    "\n",
    "# Rename the column to 'acceptance_rate'\n",
    "participant_acceptance_rate.rename(columns={'acceptance': 'acceptance_rate'}, inplace=True)\n",
    "\n",
    "#print(block_acceptance_rate.head())\n",
    "\n",
    "lars_data = pd.read_csv(\"Pilot Data/lars_results_scored.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Preview the aggregated subscale data\n",
    "#print(subscale_avg.head())\n",
    "\n",
    "# Merge the subscale averages with the block acceptance rates based on participant_id and block\n",
    "merged_data = pd.merge(lars_data, participant_acceptance_rate, on=['participant_id'])\n",
    "\n",
    "# Preview the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Initialize a dictionary to store correlation coefficients and p-values\n",
    "correlation_results = {}\n",
    "\n",
    "\n",
    "correlation, p_value = stats.pearsonr(merged_data['Intellectual_Curiosity'], merged_data['acceptance_rate'])\n",
    "correlation_results['Intellectual_Curiosity'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Emotional_Responsiveness'], merged_data['acceptance_rate'])\n",
    "correlation_results['Emotional_Responsiveness'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Self_Awareness'], merged_data['acceptance_rate'])\n",
    "correlation_results['Self_Awareness'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Action_Initiation'], merged_data['acceptance_rate'])\n",
    "correlation_results['Action_Initiation'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Total_LARS_Score'], merged_data['acceptance_rate'])\n",
    "correlation_results['Total_LARS_Score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "# Store the results\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlation between subscale scores and acceptance rates (with p-values):\")\n",
    "for subscale, results in correlation_results.items():\n",
    "    print(f\"{subscale}: Correlation = {results['correlation']:.3f}, p-value = {results['p_value']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third we correlate QUIP with overall Acceptance Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             participant_id  gambling_score  sex_score  buying_score  \\\n",
      "0  67ac2151e5b37e0b91a5af0e               0          4             5   \n",
      "1  66b5a7ae36e5b931db863954               0          2             2   \n",
      "2  678fa07cd72c816bac76bda5               0          3             6   \n",
      "3  6785b7dd6705050739feb0ad               0          1             2   \n",
      "4  5adef850eb60400001539109               5          0             0   \n",
      "\n",
      "   eating_score  hobbyism_punding_score  icd_total  quip_rs_total  \\\n",
      "0             7                      12         16             28   \n",
      "1             3                       4          7             11   \n",
      "2             8                      15         17             32   \n",
      "3             2                       4          5              9   \n",
      "4             0                       0          5              5   \n",
      "\n",
      "   acceptance_rate  \n",
      "0         0.698333  \n",
      "1         0.433333  \n",
      "2         0.665000  \n",
      "3         0.536667  \n",
      "4         0.073333  \n",
      "Correlation between subscale scores and acceptance rates (with p-values):\n",
      "icd_total: Correlation = 0.487, p-value = 0.153\n",
      "quip_rs_total: Correlation = 0.483, p-value = 0.157\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Load the EBDM task data\n",
    "df = pd.read_csv(\"Pilot Data/all_trials.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Calculate the overall acceptance rate per block for each participant\n",
    "participant_acceptance_rate = df.groupby(['participant_id'])['acceptance'].mean().reset_index()\n",
    "\n",
    "# Rename the column to 'acceptance_rate'\n",
    "participant_acceptance_rate.rename(columns={'acceptance': 'acceptance_rate'}, inplace=True)\n",
    "\n",
    "#print(block_acceptance_rate.head())\n",
    "\n",
    "quip_data = pd.read_csv(\"Pilot Data/quip_results_scored.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Preview the aggregated subscale data\n",
    "#print(subscale_avg.head())\n",
    "\n",
    "# Merge the subscale averages with the block acceptance rates based on participant_id and block\n",
    "merged_data = pd.merge(quip_data, participant_acceptance_rate, on=['participant_id'])\n",
    "\n",
    "# Preview the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Initialize a dictionary to store correlation coefficients and p-values\n",
    "correlation_results = {}\n",
    "\n",
    "\n",
    "correlation, p_value = stats.pearsonr(merged_data['icd_total'], merged_data['acceptance_rate'])\n",
    "correlation_results['icd_total'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['quip_rs_total'], merged_data['acceptance_rate'])\n",
    "correlation_results['quip_rs_total'] = {'correlation': correlation, 'p_value': p_value}\n",
    "\n",
    "# Store the results\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlation between subscale scores and acceptance rates (with p-values):\")\n",
    "for subscale, results in correlation_results.items():\n",
    "    print(f\"{subscale}: Correlation = {results['correlation']:.3f}, p-value = {results['p_value']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate correlations with difference in acceptance rates between conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             participant_id  acceptance_diff\n",
      "0  5adef850eb60400001539109         0.060000\n",
      "1  5d7472ad3bc4020015f3bb56         0.170000\n",
      "2  63cff262503b56190be3eb18         0.066667\n",
      "3  6562025a6e3331528cf8fb3d         0.000000\n",
      "4  6612c945cebe319d923b80f8         0.080000\n",
      "5  66b5a7ae36e5b931db863954         0.020000\n",
      "6  6773fc8590d7b54b0d580e6b        -0.006406\n",
      "7  6785b7dd6705050739feb0ad         0.246667\n",
      "8  678fa07cd72c816bac76bda5         0.063333\n",
      "9  67ac2151e5b37e0b91a5af0e         0.183333\n",
      "             participant_id  das_executive_score  das_emotional_score  \\\n",
      "0  67ac2151e5b37e0b91a5af0e                    4                   12   \n",
      "1  66b5a7ae36e5b931db863954                    3                   10   \n",
      "2  678fa07cd72c816bac76bda5                    3                   10   \n",
      "3  6785b7dd6705050739feb0ad                    5                   15   \n",
      "4  5adef850eb60400001539109                    8                   18   \n",
      "\n",
      "   das_initiation_score  das_total_score  acceptance_delay_0  \\\n",
      "0                    10               26            0.790000   \n",
      "1                    14               27            0.443333   \n",
      "2                     7               20            0.696667   \n",
      "3                    13               33            0.660000   \n",
      "4                    13               39            0.103333   \n",
      "\n",
      "   acceptance_delay_1  acceptance_diff  \n",
      "0            0.606667         0.183333  \n",
      "1            0.423333         0.020000  \n",
      "2            0.633333         0.063333  \n",
      "3            0.413333         0.246667  \n",
      "4            0.043333         0.060000  \n",
      "Correlation between subscale scores and acceptance rates (with p-values):\n",
      "das_executive_score: Correlation = -0.109, p-value = 0.764\n",
      "das_emotional_score: Correlation = 0.387, p-value = 0.269\n",
      "das_initiation_score: Correlation = 0.248, p-value = 0.490\n",
      "das_total_score: Correlation = 0.224, p-value = 0.533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV into a DataFrame\n",
    "df = pd.read_csv(\"Pilot Data/all_trials.csv\")  # Replace with your file path\n",
    "\n",
    "# Step 1: Group by participant_id and delay, then calculate mean acceptance\n",
    "acceptance_rates = df.groupby(['participant_id', 'delay'])['acceptance'].mean().reset_index()\n",
    "\n",
    "# Step 2: Pivot to wide format (delays become columns)\n",
    "pivot_df = acceptance_rates.pivot(index='participant_id', columns='delay', values='acceptance').reset_index()\n",
    "\n",
    "# Optional: Rename delay columns for clarity\n",
    "pivot_df.columns.name = None  # remove axis name\n",
    "pivot_df = pivot_df.rename(columns={0: 'acceptance_delay_0', 1: 'acceptance_delay_1'})\n",
    "\n",
    "# Step 3: Calculate the difference in acceptance rate between delay 0 and delay 1\n",
    "pivot_df['acceptance_diff'] = pivot_df['acceptance_delay_0'] - pivot_df['acceptance_delay_1']\n",
    "\n",
    "# Resulting DataFrame\n",
    "print(pivot_df[['participant_id', 'acceptance_diff']])\n",
    "\n",
    "das_data = pd.read_csv(\"Pilot Data/das_scored_results.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Preview the aggregated subscale data\n",
    "#print(subscale_avg.head())\n",
    "\n",
    "# Merge the subscale averages with the block acceptance rates based on participant_id and block\n",
    "merged_data = pd.merge(das_data, pivot_df, on=['participant_id'])\n",
    "\n",
    "# Preview the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Initialize a dictionary to store correlation coefficients and p-values\n",
    "correlation_results = {}\n",
    "\n",
    "\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_executive_score'], merged_data['acceptance_diff'])\n",
    "correlation_results['das_executive_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_emotional_score'], merged_data['acceptance_diff'])\n",
    "correlation_results['das_emotional_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_initiation_score'], merged_data['acceptance_diff'])\n",
    "correlation_results['das_initiation_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['das_total_score'], merged_data['acceptance_diff'])\n",
    "correlation_results['das_total_score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "# Store the results\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlation between subscale scores and acceptance rates (with p-values):\")\n",
    "for subscale, results in correlation_results.items():\n",
    "    print(f\"{subscale}: Correlation = {results['correlation']:.3f}, p-value = {results['p_value']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             participant_id  acceptance_diff\n",
      "0  5adef850eb60400001539109         0.060000\n",
      "1  5d7472ad3bc4020015f3bb56         0.170000\n",
      "2  63cff262503b56190be3eb18         0.066667\n",
      "3  6562025a6e3331528cf8fb3d         0.000000\n",
      "4  6612c945cebe319d923b80f8         0.080000\n",
      "5  66b5a7ae36e5b931db863954         0.020000\n",
      "6  6773fc8590d7b54b0d580e6b        -0.006406\n",
      "7  6785b7dd6705050739feb0ad         0.246667\n",
      "8  678fa07cd72c816bac76bda5         0.063333\n",
      "9  67ac2151e5b37e0b91a5af0e         0.183333\n",
      "             participant_id  Intellectual_Curiosity  Motivation  Interest  \\\n",
      "0  67ac2151e5b37e0b91a5af0e                      20           7         5   \n",
      "1  66b5a7ae36e5b931db863954                      28           8         5   \n",
      "2  678fa07cd72c816bac76bda5                      33           9         4   \n",
      "3  6785b7dd6705050739feb0ad                      44           8         6   \n",
      "4  5adef850eb60400001539109                      47          12         6   \n",
      "\n",
      "   Novelty_Seeking  Social_Life  Emotional_Responsiveness  Self_Awareness  \\\n",
      "0                4            4                        24              16   \n",
      "1                6            9                        35               4   \n",
      "2                8           12                        27               6   \n",
      "3               10           20                        24               7   \n",
      "4               12           17                        25              16   \n",
      "\n",
      "   Action_Initiation  Everyday_Productivity  Initiative  Total_LARS_Score  \\\n",
      "0                 10                      8           2                57   \n",
      "1                  6                      4           2                38   \n",
      "2                 12                      7           5                59   \n",
      "3                 15                      9           6                77   \n",
      "4                 12                      6           6                85   \n",
      "\n",
      "   acceptance_delay_0  acceptance_delay_1  acceptance_diff  \n",
      "0            0.790000            0.606667         0.183333  \n",
      "1            0.443333            0.423333         0.020000  \n",
      "2            0.696667            0.633333         0.063333  \n",
      "3            0.660000            0.413333         0.246667  \n",
      "4            0.103333            0.043333         0.060000  \n",
      "Correlation between subscale scores and acceptance rates (with p-values):\n",
      "Intellectual_Curiosity: Correlation = 0.176, p-value = 0.627\n",
      "Emotional_Responsiveness: Correlation = -0.635, p-value = 0.049\n",
      "Self_Awareness: Correlation = 0.196, p-value = 0.587\n",
      "Action_Initiation: Correlation = 0.197, p-value = 0.585\n",
      "Total_LARS_Score: Correlation = 0.307, p-value = 0.388\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV into a DataFrame\n",
    "df = pd.read_csv(\"Pilot Data/all_trials.csv\")  # Replace with your file path\n",
    "\n",
    "# Step 1: Group by participant_id and delay, then calculate mean acceptance\n",
    "acceptance_rates = df.groupby(['participant_id', 'delay'])['acceptance'].mean().reset_index()\n",
    "\n",
    "# Step 2: Pivot to wide format (delays become columns)\n",
    "pivot_df = acceptance_rates.pivot(index='participant_id', columns='delay', values='acceptance').reset_index()\n",
    "\n",
    "# Optional: Rename delay columns for clarity\n",
    "pivot_df.columns.name = None  # remove axis name\n",
    "pivot_df = pivot_df.rename(columns={0: 'acceptance_delay_0', 1: 'acceptance_delay_1'})\n",
    "\n",
    "# Step 3: Calculate the difference in acceptance rate between delay 0 and delay 1\n",
    "pivot_df['acceptance_diff'] = pivot_df['acceptance_delay_0'] - pivot_df['acceptance_delay_1']\n",
    "\n",
    "# Resulting DataFrame\n",
    "print(pivot_df[['participant_id', 'acceptance_diff']])\n",
    "\n",
    "lars_data = pd.read_csv(\"Pilot Data/lars_results_scored.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Preview the aggregated subscale data\n",
    "#print(subscale_avg.head())\n",
    "\n",
    "# Merge the subscale averages with the block acceptance rates based on participant_id and block\n",
    "merged_data = pd.merge(lars_data, pivot_df, on=['participant_id'])\n",
    "\n",
    "# Preview the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Initialize a dictionary to store correlation coefficients and p-values\n",
    "correlation_results = {}\n",
    "\n",
    "\n",
    "correlation, p_value = stats.pearsonr(merged_data['Intellectual_Curiosity'], merged_data['acceptance_diff'])\n",
    "correlation_results['Intellectual_Curiosity'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Emotional_Responsiveness'], merged_data['acceptance_diff'])\n",
    "correlation_results['Emotional_Responsiveness'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Self_Awareness'], merged_data['acceptance_diff'])\n",
    "correlation_results['Self_Awareness'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Action_Initiation'], merged_data['acceptance_diff'])\n",
    "correlation_results['Action_Initiation'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['Total_LARS_Score'], merged_data['acceptance_diff'])\n",
    "correlation_results['Total_LARS_Score'] = {'correlation': correlation, 'p_value': p_value}\n",
    "# Store the results\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlation between subscale scores and acceptance rates (with p-values):\")\n",
    "for subscale, results in correlation_results.items():\n",
    "    print(f\"{subscale}: Correlation = {results['correlation']:.3f}, p-value = {results['p_value']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             participant_id  acceptance_diff\n",
      "0  5adef850eb60400001539109         0.060000\n",
      "1  5d7472ad3bc4020015f3bb56         0.170000\n",
      "2  63cff262503b56190be3eb18         0.066667\n",
      "3  6562025a6e3331528cf8fb3d         0.000000\n",
      "4  6612c945cebe319d923b80f8         0.080000\n",
      "5  66b5a7ae36e5b931db863954         0.020000\n",
      "6  6773fc8590d7b54b0d580e6b        -0.006406\n",
      "7  6785b7dd6705050739feb0ad         0.246667\n",
      "8  678fa07cd72c816bac76bda5         0.063333\n",
      "9  67ac2151e5b37e0b91a5af0e         0.183333\n",
      "             participant_id  gambling_score  sex_score  buying_score  \\\n",
      "0  67ac2151e5b37e0b91a5af0e               0          4             5   \n",
      "1  66b5a7ae36e5b931db863954               0          2             2   \n",
      "2  678fa07cd72c816bac76bda5               0          3             6   \n",
      "3  6785b7dd6705050739feb0ad               0          1             2   \n",
      "4  5adef850eb60400001539109               5          0             0   \n",
      "\n",
      "   eating_score  hobbyism_punding_score  icd_total  quip_rs_total  \\\n",
      "0             7                      12         16             28   \n",
      "1             3                       4          7             11   \n",
      "2             8                      15         17             32   \n",
      "3             2                       4          5              9   \n",
      "4             0                       0          5              5   \n",
      "\n",
      "   acceptance_delay_0  acceptance_delay_1  acceptance_diff  \n",
      "0            0.790000            0.606667         0.183333  \n",
      "1            0.443333            0.423333         0.020000  \n",
      "2            0.696667            0.633333         0.063333  \n",
      "3            0.660000            0.413333         0.246667  \n",
      "4            0.103333            0.043333         0.060000  \n",
      "Correlation between subscale scores and acceptance rates (with p-values):\n",
      "icd_total: Correlation = -0.153, p-value = 0.673\n",
      "quip_rs_total: Correlation = -0.226, p-value = 0.529\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV into a DataFrame\n",
    "df = pd.read_csv(\"Pilot Data/all_trials.csv\")  # Replace with your file path\n",
    "\n",
    "# Step 1: Group by participant_id and delay, then calculate mean acceptance\n",
    "acceptance_rates = df.groupby(['participant_id', 'delay'])['acceptance'].mean().reset_index()\n",
    "\n",
    "# Step 2: Pivot to wide format (delays become columns)\n",
    "pivot_df = acceptance_rates.pivot(index='participant_id', columns='delay', values='acceptance').reset_index()\n",
    "\n",
    "# Optional: Rename delay columns for clarity\n",
    "pivot_df.columns.name = None  # remove axis name\n",
    "pivot_df = pivot_df.rename(columns={0: 'acceptance_delay_0', 1: 'acceptance_delay_1'})\n",
    "\n",
    "# Step 3: Calculate the difference in acceptance rate between delay 0 and delay 1\n",
    "pivot_df['acceptance_diff'] = pivot_df['acceptance_delay_0'] - pivot_df['acceptance_delay_1']\n",
    "\n",
    "# Resulting DataFrame\n",
    "print(pivot_df[['participant_id', 'acceptance_diff']])\n",
    "\n",
    "\n",
    "quip_data = pd.read_csv(\"Pilot Data/quip_results_scored.csv\")  # Replace with the actual file path\n",
    "\n",
    "# Preview the aggregated subscale data\n",
    "#print(subscale_avg.head())\n",
    "\n",
    "# Merge the subscale averages with the block acceptance rates based on participant_id and block\n",
    "merged_data = pd.merge(quip_data, pivot_df, on=['participant_id'])\n",
    "\n",
    "# Preview the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Initialize a dictionary to store correlation coefficients and p-values\n",
    "correlation_results = {}\n",
    "\n",
    "\n",
    "correlation, p_value = stats.pearsonr(merged_data['icd_total'], merged_data['acceptance_diff'])\n",
    "correlation_results['icd_total'] = {'correlation': correlation, 'p_value': p_value}\n",
    "correlation, p_value = stats.pearsonr(merged_data['quip_rs_total'], merged_data['acceptance_diff'])\n",
    "correlation_results['quip_rs_total'] = {'correlation': correlation, 'p_value': p_value}\n",
    "\n",
    "# Store the results\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlation between subscale scores and acceptance rates (with p-values):\")\n",
    "for subscale, results in correlation_results.items():\n",
    "    print(f\"{subscale}: Correlation = {results['correlation']:.3f}, p-value = {results['p_value']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
